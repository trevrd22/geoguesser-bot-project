{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "851bcc0c",
   "metadata": {},
   "source": [
    "### Project Road Map ###\n",
    "\n",
    "0. Install Anaconda/Miniconda if you have not and set it up to use it as your kernel.\n",
    "\n",
    "1. Obtain and configure a pre-trained CNN\n",
    "\n",
    "2. Import and configure a google streetview dataset\n",
    "\n",
    "3. Create helper functions to allow for more efficient model training and experimentation and install weights and biases visualizer to integrate in functions.\n",
    "\n",
    "4. Run, compare, and bugfix to attain < 1 km accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15204db9",
   "metadata": {},
   "source": [
    "## 1. Obtain and configure a pre-trained CNN ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f905597",
   "metadata": {},
   "source": [
    "Import a CNN Model from Pytorch Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3acad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trevor Drummond\\miniconda3\\envs\\geoguessr\\Lib\\site-packages\\torch\\__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Trevor Drummond\\miniconda3\\envs\\geoguessr\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable\n",
       "=============================================================================================================================\n",
       "GeoClassifier (GeoClassifier)                 [32, 3, 224, 224]    [32, 2]              --                   Partial\n",
       "├─ResNet (backbone)                           [32, 3, 224, 224]    [32, 2048]           --                   False\n",
       "│    └─Conv2d (conv1)                         [32, 3, 224, 224]    [32, 64, 112, 112]   (9,408)              False\n",
       "│    └─BatchNorm2d (bn1)                      [32, 64, 112, 112]   [32, 64, 112, 112]   (128)                False\n",
       "│    └─ReLU (relu)                            [32, 64, 112, 112]   [32, 64, 112, 112]   --                   --\n",
       "│    └─MaxPool2d (maxpool)                    [32, 64, 112, 112]   [32, 64, 56, 56]     --                   --\n",
       "│    └─Sequential (layer1)                    [32, 64, 56, 56]     [32, 256, 56, 56]    --                   False\n",
       "│    │    └─Bottleneck (0)                    [32, 64, 56, 56]     [32, 256, 56, 56]    (75,008)             False\n",
       "│    │    └─Bottleneck (1)                    [32, 256, 56, 56]    [32, 256, 56, 56]    (70,400)             False\n",
       "│    │    └─Bottleneck (2)                    [32, 256, 56, 56]    [32, 256, 56, 56]    (70,400)             False\n",
       "│    └─Sequential (layer2)                    [32, 256, 56, 56]    [32, 512, 28, 28]    --                   False\n",
       "│    │    └─Bottleneck (0)                    [32, 256, 56, 56]    [32, 512, 28, 28]    (379,392)            False\n",
       "│    │    └─Bottleneck (1)                    [32, 512, 28, 28]    [32, 512, 28, 28]    (280,064)            False\n",
       "│    │    └─Bottleneck (2)                    [32, 512, 28, 28]    [32, 512, 28, 28]    (280,064)            False\n",
       "│    │    └─Bottleneck (3)                    [32, 512, 28, 28]    [32, 512, 28, 28]    (280,064)            False\n",
       "│    └─Sequential (layer3)                    [32, 512, 28, 28]    [32, 1024, 14, 14]   --                   False\n",
       "│    │    └─Bottleneck (0)                    [32, 512, 28, 28]    [32, 1024, 14, 14]   (1,512,448)          False\n",
       "│    │    └─Bottleneck (1)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   (1,117,184)          False\n",
       "│    │    └─Bottleneck (2)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   (1,117,184)          False\n",
       "│    │    └─Bottleneck (3)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   (1,117,184)          False\n",
       "│    │    └─Bottleneck (4)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   (1,117,184)          False\n",
       "│    │    └─Bottleneck (5)                    [32, 1024, 14, 14]   [32, 1024, 14, 14]   (1,117,184)          False\n",
       "│    └─Sequential (layer4)                    [32, 1024, 14, 14]   [32, 2048, 7, 7]     --                   False\n",
       "│    │    └─Bottleneck (0)                    [32, 1024, 14, 14]   [32, 2048, 7, 7]     (6,039,552)          False\n",
       "│    │    └─Bottleneck (1)                    [32, 2048, 7, 7]     [32, 2048, 7, 7]     (4,462,592)          False\n",
       "│    │    └─Bottleneck (2)                    [32, 2048, 7, 7]     [32, 2048, 7, 7]     (4,462,592)          False\n",
       "│    └─AdaptiveAvgPool2d (avgpool)            [32, 2048, 7, 7]     [32, 2048, 1, 1]     --                   --\n",
       "│    └─Identity (fc)                          [32, 2048]           [32, 2048]           --                   --\n",
       "├─Linear (shared_fc)                          [32, 2048]           [32, 512]            1,049,088            True\n",
       "├─Linear (country_head)                       [32, 512]            [32, 1]              513                  True\n",
       "├─Linear (region_head)                        [32, 513]            [32, 1]              514                  True\n",
       "├─Linear (subregion_head)                     [32, 513]            [32, 1]              514                  True\n",
       "├─Linear (coord_regressor)                    [32, 513]            [32, 2]              1,028                True\n",
       "=============================================================================================================================\n",
       "Total params: 24,559,689\n",
       "Trainable params: 1,051,657\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (Units.GIGABYTES): 130.82\n",
       "=============================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5690.49\n",
       "Params size (MB): 98.24\n",
       "Estimated Total Size (MB): 5808.00\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__file__)\n",
    "import torchvision\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchinfo import summary\n",
    "\n",
    "#this makes it so that if your gpu is available the model will use it\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "#create model as a child of nn.Module\n",
    "class GeoClassifier(nn.Module):\n",
    "    def __init__ (self,num_countries,num_regions,num_subregions):\n",
    "        super().__init__()\n",
    "        \n",
    "        #load resnet backbone and remove imagenet classifier, replacing it with nn.Identity which acts as a dummy layer\n",
    "        self.backbone = resnet50(weights = ResNet50_Weights)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        #freeze feature layers\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad=False\n",
    "        \n",
    "        \n",
    "        #create a shared fully connected layer to reduce dimensionality (make it easier for the model to learn patterns, may revisit later)\n",
    "        self.shared_fc = nn.Linear(2048,512)\n",
    "        \n",
    "        #create three hierarchical classification heads that rely on the previous label, this is our guessing output!\n",
    "        self.country_head = nn.Linear(512, num_countries) #takes in the 512 inputs spit out by the previous layer and selects from the number of countries we have\n",
    "        self.region_head = nn.Linear(512 + num_countries, num_regions) #makes it so that we can feed this layer the 512 values that come from the features layer, as well as the result of the countries label\n",
    "        self.subregion_head = nn.Linear(512 + num_regions, num_subregions)\n",
    "        \n",
    "        #add a final regression head that predicts the lat and lon the photo is offset from the selected subregion\n",
    "        self.coord_regressor = nn.Linear(512 + num_subregions, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #extract image features from the resnet backbone\n",
    "        x = self.backbone(x)\n",
    "        x = self.shared_fc(x)\n",
    "        \n",
    "        #predict country\n",
    "        country_logits = self.country_head(x)\n",
    "        country_soft = torch.softmax(country_logits, dim = 1) #converting for a logits (numeric value) to a probability, these are used internally to influence the next guess, but not exported\n",
    "        \n",
    "        #predict region conditioned on country\n",
    "        region_input = torch.cat([x,country_soft], dim = 1) #concatenates the features pulled from the features layer with the probabilities of which country is most likely\n",
    "        region_logits = self.region_head(region_input)\n",
    "        region_soft = torch.softmax(region_logits, dim = 1)\n",
    "        \n",
    "        #predict region conditioned on country\n",
    "        subregion_input = torch.cat([x,region_soft], dim = 1)\n",
    "        subregion_logits = self.subregion_head(subregion_input)\n",
    "        subregion_soft = torch.softmax(subregion_logits, dim = 1)\n",
    "        \n",
    "        #predict coord deltas conditioned on city\n",
    "        coord_input = torch.cat([x,subregion_soft], dim = 1)\n",
    "        delta_coords = self.coord_regressor(coord_input)\n",
    "        \n",
    "        return {\n",
    "    \"country_logits\": country_logits,\n",
    "    \"region_logits\": region_logits,\n",
    "    \"city_logits\": subregion_logits,\n",
    "    \"delta_coords\": delta_coords\n",
    "}\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#checking output\n",
    "model = GeoClassifier(1,1,1).to(device)\n",
    "summary(model = model, input_size = (32,3,224,224), col_names = [\"input_size\",\"output_size\",\"num_params\",\"trainable\"], col_width = 20, row_settings=[\"var_names\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoguessr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
